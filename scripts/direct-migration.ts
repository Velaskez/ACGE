/**
 * ðŸ”§ Migration directe via l'API Supabase
 */

import { config } from 'dotenv'
import { createClient } from '@supabase/supabase-js'
import { join } from 'path'

async function directMigration() {
  console.log('ðŸ”§ Migration directe des colonnes de fichier\n')
  
  try {
    // 1. Charger les variables d'environnement
    const envPath = join(process.cwd(), '.env.local')
    config({ path: envPath })
    
    const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
    const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY
    
    if (!supabaseUrl || !supabaseServiceKey) {
      throw new Error('Variables d\'environnement Supabase manquantes')
    }
    
    console.log('âœ… Configuration Supabase chargÃ©e')
    
    // 2. CrÃ©er le client Supabase
    const supabase = createClient(supabaseUrl, supabaseServiceKey)
    
    // 3. VÃ©rifier la structure actuelle
    console.log('\nðŸ“Š VÃ©rification de la structure actuelle...')
    
    const { data: testDoc, error: testError } = await supabase
      .from('documents')
      .select('*')
      .limit(1)
    
    if (testError) {
      console.error('âŒ Erreur lors de la vÃ©rification:', testError)
      return
    }
    
    if (testDoc && testDoc.length > 0) {
      console.log('ðŸ“‹ Colonnes actuelles:', Object.keys(testDoc[0]).join(', '))
      
      // VÃ©rifier si les colonnes de fichier existent dÃ©jÃ 
      const hasFileColumns = ['file_name', 'file_size', 'file_type', 'file_path'].every(
        col => col in testDoc[0]
      )
      
      if (hasFileColumns) {
        console.log('âœ… Les colonnes de fichier existent dÃ©jÃ !')
        return
      }
    }
    
    // 4. Utiliser l'API REST avec une requÃªte SQL brute
    console.log('\nðŸ“ Ajout des colonnes via requÃªte SQL brute...')
    
    const alterQueries = [
      'ALTER TABLE documents ADD COLUMN IF NOT EXISTS file_name TEXT',
      'ALTER TABLE documents ADD COLUMN IF NOT EXISTS file_size INTEGER',
      'ALTER TABLE documents ADD COLUMN IF NOT EXISTS file_type TEXT',
      'ALTER TABLE documents ADD COLUMN IF NOT EXISTS file_path TEXT',
      'ALTER TABLE documents ADD COLUMN IF NOT EXISTS url TEXT',
      'ALTER TABLE documents ADD COLUMN IF NOT EXISTS tags JSONB DEFAULT \'[]\'::jsonb',
      'ALTER TABLE documents ADD COLUMN IF NOT EXISTS is_public BOOLEAN DEFAULT FALSE'
    ]
    
    for (const query of alterQueries) {
      try {
        console.log(`ðŸ“‹ ExÃ©cution: ${query}`)
        
        // Utiliser l'endpoint SQL de Supabase
        const response = await fetch(`${supabaseUrl}/rest/v1/rpc/exec`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${supabaseServiceKey}`,
            'apikey': supabaseServiceKey
          },
          body: JSON.stringify({ sql: query })
        })
        
        if (response.ok) {
          console.log('âœ… RequÃªte exÃ©cutÃ©e avec succÃ¨s')
        } else {
          const errorText = await response.text()
          console.log('âš ï¸ Erreur:', errorText)
        }
        
      } catch (err) {
        console.log('âš ï¸ Erreur lors de l\'exÃ©cution:', err)
      }
    }
    
    // 5. Alternative: Utiliser l'API GraphQL si disponible
    console.log('\nðŸ”„ Tentative via API GraphQL...')
    
    try {
      const graphqlResponse = await fetch(`${supabaseUrl}/graphql/v1`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${supabaseServiceKey}`,
          'apikey': supabaseServiceKey
        },
        body: JSON.stringify({
          query: `
            mutation {
              exec_sql(sql: "ALTER TABLE documents ADD COLUMN IF NOT EXISTS file_name TEXT")
            }
          `
        })
      })
      
      if (graphqlResponse.ok) {
        console.log('âœ… RequÃªte GraphQL exÃ©cutÃ©e')
      } else {
        console.log('âš ï¸ GraphQL non disponible')
      }
    } catch (err) {
      console.log('âš ï¸ GraphQL non disponible:', err)
    }
    
    // 6. VÃ©rifier la nouvelle structure
    console.log('\nðŸ“Š VÃ©rification de la nouvelle structure...')
    
    const { data: finalTest, error: finalError } = await supabase
      .from('documents')
      .select('*')
      .limit(1)
    
    if (finalError) {
      console.error('âŒ Erreur lors de la vÃ©rification finale:', finalError)
    } else if (finalTest && finalTest.length > 0) {
      console.log('âœ… Structure mise Ã  jour:')
      console.log('ðŸ“‹ Nouvelles colonnes:', Object.keys(finalTest[0]).join(', '))
      
      // VÃ©rifier les colonnes de fichier
      const fileColumns = ['file_name', 'file_size', 'file_type', 'file_path', 'url', 'tags', 'is_public']
      const missingColumns = fileColumns.filter(col => !(col in finalTest[0]))
      
      if (missingColumns.length === 0) {
        console.log('ðŸŽ‰ Toutes les colonnes de fichier ont Ã©tÃ© ajoutÃ©es avec succÃ¨s!')
      } else {
        console.log('âš ï¸ Colonnes manquantes:', missingColumns.join(', '))
        console.log('\nðŸ“ Instructions manuelles:')
        console.log('1. Allez dans votre projet Supabase')
        console.log('2. Ouvrez l\'Ã©diteur SQL')
        console.log('3. ExÃ©cutez ces requÃªtes:')
        missingColumns.forEach(col => {
          const type = col === 'file_size' ? 'INTEGER' : 
                      col === 'tags' ? 'JSONB DEFAULT \'[]\'::jsonb' :
                      col === 'is_public' ? 'BOOLEAN DEFAULT FALSE' : 'TEXT'
          console.log(`   ALTER TABLE documents ADD COLUMN IF NOT EXISTS ${col} ${type};`)
        })
      }
    }
    
    console.log('\nðŸŽ‰ Migration terminÃ©e!')
    
  } catch (error) {
    console.error('ðŸ’¥ Erreur lors de la migration:', error)
  }
}

// ExÃ©cuter la migration
directMigration()
